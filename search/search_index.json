{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#multispectral-image-tool","title":"Multispectral Image Tool","text":""},{"location":"#description","title":"Description","text":"<p>This python library contains tools to manipulate multispectral image files captured by the Micasense RedEdge-P sensor. </p> <p>The input image file must be composed of six channels:</p> <ol> <li>Red band reflectance</li> <li>Green band reflectance</li> <li>Blue band reflectance</li> <li>Red Edge band reflectance</li> <li>Near-infrared band reflectance</li> <li>Binary cutline (optional)</li> </ol>"},{"location":"#installation","title":"Installation","text":"<p>The library can be installed with <code>pip</code>.</p> <pre><code>pip install ms-image-tool\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of <code>MIT License</code>.</p>"},{"location":"API%20Reference/Image%20Class/","title":"Image Class","text":"<p>This class is used to represent a five-band multispectral image object.</p> <p>The bands/channels of the image file should be ordered as follows:</p> <ol> <li>Red (R)</li> <li>Green (G)</li> <li>Blue (B)</li> <li>Red Edge (RE)</li> <li>Near Infrared (NIR)</li> <li>Cutline (optional)</li> </ol> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>str</code> <p>Path to the .tiff file.</p> required <code>cutline_included</code> <code>bool</code> <p>True if a cutline binary mask is included as the sixth band of the image.</p> <code>False</code> <p>Examples:</p> <p>Loading an image from a .tiff file and accessing its shape property:</p> <pre><code>&gt;&gt;&gt; image = Image(input_path = \"../data/sample/sample-image.tif\")\n&gt;&gt;&gt; image.shape\n(500, 500)\n</code></pre> Source code in <code>ms_image_tool/image.py</code> <pre><code>class Image:\n    \"\"\"\n    This class is used to represent a five-band multispectral image object.\n\n    The bands/channels of the image file should be ordered as follows:\n\n    1. Red (R)\n    2. Green (G)\n    3. Blue (B)\n    4. Red Edge (RE)\n    5. Near Infrared (NIR)\n    6. Cutline (optional)\n\n    Parameters:\n        input_path (str): Path to the .tiff file.\n        cutline_included (bool): True if a cutline binary mask is included as the sixth band of the image.\n\n    Examples:\n        Loading an image from a .tiff file and accessing its shape property:\n\n        &gt;&gt;&gt; image = Image(input_path = \"../data/sample/sample-image.tif\")\n        &gt;&gt;&gt; image.shape\n        (500, 500)\n    \"\"\"\n\n    def __init__(self, input_path: str, cutline_included: bool = False) -&gt; None:\n        self.path = input_path\n        tensor = self._load_tiff(input_path)\n\n        self.height = tensor.shape[0]\n        self.width = tensor.shape[1]\n        self.shape = (self.height, self.width)\n\n        self.red = self._correct_bands(tensor[:, :, 0])\n        self.green = self._correct_bands(tensor[:, :, 1])\n        self.blue = self._correct_bands(tensor[:, :, 2])\n        self.rededge = self._correct_bands(tensor[:, :, 3])\n        self.nir = self._correct_bands(tensor[:, :, 4])\n\n        if cutline_included:\n            self.cutline = np.uint8(\n                (tensor[:, :, 5] - np.min(tensor[:, :, 5]))\n                / (np.max(tensor[:, :, 5]) - np.min(tensor[:, :, 5]))\n            )\n            self.cutline = self.cutline.astype(bool)\n        else:\n            self.cutline = np.ones((self.height, self.width), dtype=bool)\n\n    def _load_tiff(self, input_path: str) -&gt; np.ndarray:\n        \"\"\"\n        Load an image from a .tiff file and return it as a numpy array.\n\n        Parameters:\n            input_path (str): Path to the .tiff file.\n        \"\"\"\n        possible_extensions = [\"tiff\", \"tif\"]\n        extension = input_path.split(\".\")[-1]\n\n        if extension not in possible_extensions:\n            raise ValueError(\"Invalid file extension. Please provide a .tiff file.\")\n\n        return tifffile.imread(input_path)\n\n    def _correct_bands(self, tensor: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Correct values in the input tensor to be within the range of 0-1.\n\n        Parameters:\n            tensor (np.ndarray): Single band of the input image.\n        \"\"\"\n        tensor[np.where(tensor &gt; 1)] = 1\n        tensor[np.where(tensor &lt; 0)] = 0\n        return tensor\n\n    def _normalize(\n        self, tensor: np.ndarray, min_value: float = None, max_value: float = None\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Image normalization. Adapted from Micasense Image Processing\n        (https://github.com/micasense/imageprocessing)\n\n        Parameters:\n            tensor (np.ndarray): Single band of the input image.\n            min_value (float): Minimum value for normalization.\n            max_value (float): Maximum value for normalization.\n\n        Outputs:\n            norm (np.ndarray): Normalized image.\n        \"\"\"\n        width, height = tensor.shape\n        norm = np.zeros((width, height), dtype=np.float32)\n\n        if min_value is not None and max_value is not None:\n            norm = (tensor - min_value) / (max_value - min_value)\n        else:\n            cv2.normalize(\n                tensor,\n                dst=norm,\n                alpha=0.0,\n                beta=1.0,\n                norm_type=cv2.NORM_MINMAX,\n                dtype=cv2.CV_32F,\n            )\n        norm[norm &lt; 0.0] = 0.0\n        norm[norm &gt; 1.0] = 1.0\n        return norm\n\n    def _normalized_stack(self, array: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Image Stack Normalization. Adapted from Micasense Image Processing\n        (https://github.com/micasense/imageprocessing)\n\n        Parameters:\n            array (np.ndarray): Multispectral image tensor.\n\n        Outputs:\n            im_display (np.ndarray): Normalized image stack\n        \"\"\"\n        im_display = np.zeros(\n            (array.shape[0], array.shape[1], array.shape[2]), dtype=np.float32\n        )\n\n        im_min = np.percentile(\n            array[:, :, :].flatten(), 0.5\n        )  # modify these percentiles to adjust contrast\n        im_max = np.percentile(\n            array[:, :, :].flatten(), 99.5\n        )  # for many images, 0.5 and 99.5 are good values\n\n        # for rgb true color, we use the same min and max scaling across the 3 bands to\n        # maintain the \"white balance\" of the calibrated image\n        for i in range(array.shape[-1]):\n            im_display[:, :, i] = self._normalize(array[:, :, i], im_min, im_max)\n\n        return im_display\n\n    def get_tensor(self, cutline: bool = False):\n        \"\"\"\n        Returns the image as a numpy array.\n\n        Returns:\n            tensor (np.ndarray): Image as a numpy array.\n        \"\"\"\n\n        if cutline:\n            tensor = np.zeros((self.height, self.width, 6), dtype=np.float32)\n            tensor[:, :, 5] = self.cutline\n        else:\n            tensor = np.zeros((self.height, self.width, 5), dtype=np.float32)\n\n        tensor[:, :, 0] = self.red\n        tensor[:, :, 1] = self.green\n        tensor[:, :, 2] = self.blue\n        tensor[:, :, 3] = self.rededge\n        tensor[:, :, 4] = self.nir\n\n\n\n        return tensor\n\n    def get_bgr(self):\n        \"\"\"\n        Returns the image in normalized BGR format.\n\n        Returns:\n            bgr (np.ndarray): Image in normalized BGR format.\n        \"\"\"\n        bgr = [self.blue, self.green, self.red]\n        bgr = np.moveaxis(bgr, 0, -1)\n\n        return self._normalized_stack(bgr)\n\n    def get_rgb(self):\n        \"\"\"\n        Returns the image in normalized RGB format.\n\n        Returns:\n            rgb (np.ndarray): Image in normalized RGB format.\n        \"\"\"\n        rgb = [self.red, self.green, self.blue]\n        rgb = np.moveaxis(rgb, 0, -1)\n\n        return self._normalized_stack(rgb)\n\n    def get_gray(self):\n        \"\"\"\n        Returns the image in grayscale format.\n\n        Returns:\n            gray (np.ndarray): Image in grayscale format.\n        \"\"\"\n        bgr = self.get_bgr()\n        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n        gray = gray * 255\n\n        return gray.astype(int)\n\n    def get_cir(self):\n        \"\"\"\n        Returns the image in normalized false-color (CIR) composition.\n\n        Returns:\n            cir (np.ndarray): Image in normalized CIR format.\n        \"\"\"\n        cir = [self.nir, self.red, self.green]\n        cir = np.moveaxis(cir, 0, -1)\n\n        return self._normalized_stack(cir)\n\n    def get_ndvi(self):\n        \"\"\"\n        Returns the Normalized Difference Vegetation Index (NDVI).\n        NDVI = (NIR - RED) / (NIR + RED)\n\n        Returns:\n            ndvi (np.ndarray): NDVI image.\n        \"\"\"\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            ndvi = (self.nir - self.red) / (self.nir + self.red)\n            ndvi[np.isnan(ndvi)] = 0\n            ndvi = np.clip(ndvi, -1, 1)\n            return ndvi * (self.cutline &gt; 0)\n\n    def get_gndvi(self):\n        \"\"\"\n        Returns the Green Normalized Difference Vegetation Index (GNDVI).\n        GNDVI = (NIR - GREEN) / (NIR + GREEN)\n\n        Returns:\n            gndvi (np.ndarray): GNDVI image.\n        \"\"\"\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            gndvi = (self.nir - self.green) / (self.nir + self.green)\n            gndvi[np.isnan(gndvi)] = 0\n            gndvi = np.clip(gndvi, -1, 1)\n            return gndvi * (self.cutline &gt; 0)\n\n    def get_ndre(self):\n        \"\"\"\n        Returns the Normalized Difference Red Edge (NDRE).\n        NDRE = (RE - RED) / (RE + RED)\n\n        Returns:\n            ndre (np.ndarray): NDRE image.\n        \"\"\"\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            ndre = (self.rededge - self.red) / (self.rededge + self.red)\n            ndre[np.isnan(ndre)] = 0\n            ndre = np.clip(ndre, -1, 1)\n            return ndre * (self.cutline &gt; 0)\n\n    def get_ndwi(self):\n        \"\"\"\n        Returns the Normalized Difference Water Index (NDWI).\n        NDWI = (GREEN - NIR) / (GREEN + NIR)\n\n        Returns:\n            ndwi (np.ndarray): NDWI image.\n        \"\"\"\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            ndwi = (self.green - self.nir) / (self.green + self.nir)\n            ndwi[np.isnan(ndwi)] = 0\n            ndwi = np.clip(ndwi, -1, 1)\n            return ndwi * (self.cutline &gt; 0)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_bgr","title":"<code>get_bgr()</code>","text":"<p>Returns the image in normalized BGR format.</p> <p>Returns:</p> Name Type Description <code>bgr</code> <code>ndarray</code> <p>Image in normalized BGR format.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_bgr(self):\n    \"\"\"\n    Returns the image in normalized BGR format.\n\n    Returns:\n        bgr (np.ndarray): Image in normalized BGR format.\n    \"\"\"\n    bgr = [self.blue, self.green, self.red]\n    bgr = np.moveaxis(bgr, 0, -1)\n\n    return self._normalized_stack(bgr)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_cir","title":"<code>get_cir()</code>","text":"<p>Returns the image in normalized false-color (CIR) composition.</p> <p>Returns:</p> Name Type Description <code>cir</code> <code>ndarray</code> <p>Image in normalized CIR format.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_cir(self):\n    \"\"\"\n    Returns the image in normalized false-color (CIR) composition.\n\n    Returns:\n        cir (np.ndarray): Image in normalized CIR format.\n    \"\"\"\n    cir = [self.nir, self.red, self.green]\n    cir = np.moveaxis(cir, 0, -1)\n\n    return self._normalized_stack(cir)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_gndvi","title":"<code>get_gndvi()</code>","text":"<p>Returns the Green Normalized Difference Vegetation Index (GNDVI). GNDVI = (NIR - GREEN) / (NIR + GREEN)</p> <p>Returns:</p> Name Type Description <code>gndvi</code> <code>ndarray</code> <p>GNDVI image.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_gndvi(self):\n    \"\"\"\n    Returns the Green Normalized Difference Vegetation Index (GNDVI).\n    GNDVI = (NIR - GREEN) / (NIR + GREEN)\n\n    Returns:\n        gndvi (np.ndarray): GNDVI image.\n    \"\"\"\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        gndvi = (self.nir - self.green) / (self.nir + self.green)\n        gndvi[np.isnan(gndvi)] = 0\n        gndvi = np.clip(gndvi, -1, 1)\n        return gndvi * (self.cutline &gt; 0)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_gray","title":"<code>get_gray()</code>","text":"<p>Returns the image in grayscale format.</p> <p>Returns:</p> Name Type Description <code>gray</code> <code>ndarray</code> <p>Image in grayscale format.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_gray(self):\n    \"\"\"\n    Returns the image in grayscale format.\n\n    Returns:\n        gray (np.ndarray): Image in grayscale format.\n    \"\"\"\n    bgr = self.get_bgr()\n    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n    gray = gray * 255\n\n    return gray.astype(int)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_ndre","title":"<code>get_ndre()</code>","text":"<p>Returns the Normalized Difference Red Edge (NDRE). NDRE = (RE - RED) / (RE + RED)</p> <p>Returns:</p> Name Type Description <code>ndre</code> <code>ndarray</code> <p>NDRE image.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_ndre(self):\n    \"\"\"\n    Returns the Normalized Difference Red Edge (NDRE).\n    NDRE = (RE - RED) / (RE + RED)\n\n    Returns:\n        ndre (np.ndarray): NDRE image.\n    \"\"\"\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        ndre = (self.rededge - self.red) / (self.rededge + self.red)\n        ndre[np.isnan(ndre)] = 0\n        ndre = np.clip(ndre, -1, 1)\n        return ndre * (self.cutline &gt; 0)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_ndvi","title":"<code>get_ndvi()</code>","text":"<p>Returns the Normalized Difference Vegetation Index (NDVI). NDVI = (NIR - RED) / (NIR + RED)</p> <p>Returns:</p> Name Type Description <code>ndvi</code> <code>ndarray</code> <p>NDVI image.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_ndvi(self):\n    \"\"\"\n    Returns the Normalized Difference Vegetation Index (NDVI).\n    NDVI = (NIR - RED) / (NIR + RED)\n\n    Returns:\n        ndvi (np.ndarray): NDVI image.\n    \"\"\"\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        ndvi = (self.nir - self.red) / (self.nir + self.red)\n        ndvi[np.isnan(ndvi)] = 0\n        ndvi = np.clip(ndvi, -1, 1)\n        return ndvi * (self.cutline &gt; 0)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_ndwi","title":"<code>get_ndwi()</code>","text":"<p>Returns the Normalized Difference Water Index (NDWI). NDWI = (GREEN - NIR) / (GREEN + NIR)</p> <p>Returns:</p> Name Type Description <code>ndwi</code> <code>ndarray</code> <p>NDWI image.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_ndwi(self):\n    \"\"\"\n    Returns the Normalized Difference Water Index (NDWI).\n    NDWI = (GREEN - NIR) / (GREEN + NIR)\n\n    Returns:\n        ndwi (np.ndarray): NDWI image.\n    \"\"\"\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        ndwi = (self.green - self.nir) / (self.green + self.nir)\n        ndwi[np.isnan(ndwi)] = 0\n        ndwi = np.clip(ndwi, -1, 1)\n        return ndwi * (self.cutline &gt; 0)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_rgb","title":"<code>get_rgb()</code>","text":"<p>Returns the image in normalized RGB format.</p> <p>Returns:</p> Name Type Description <code>rgb</code> <code>ndarray</code> <p>Image in normalized RGB format.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_rgb(self):\n    \"\"\"\n    Returns the image in normalized RGB format.\n\n    Returns:\n        rgb (np.ndarray): Image in normalized RGB format.\n    \"\"\"\n    rgb = [self.red, self.green, self.blue]\n    rgb = np.moveaxis(rgb, 0, -1)\n\n    return self._normalized_stack(rgb)\n</code></pre>"},{"location":"API%20Reference/Image%20Class/#ms_image_tool.image.Image.get_tensor","title":"<code>get_tensor(cutline=False)</code>","text":"<p>Returns the image as a numpy array.</p> <p>Returns:</p> Name Type Description <code>tensor</code> <code>ndarray</code> <p>Image as a numpy array.</p> Source code in <code>ms_image_tool/image.py</code> <pre><code>def get_tensor(self, cutline: bool = False):\n    \"\"\"\n    Returns the image as a numpy array.\n\n    Returns:\n        tensor (np.ndarray): Image as a numpy array.\n    \"\"\"\n\n    if cutline:\n        tensor = np.zeros((self.height, self.width, 6), dtype=np.float32)\n        tensor[:, :, 5] = self.cutline\n    else:\n        tensor = np.zeros((self.height, self.width, 5), dtype=np.float32)\n\n    tensor[:, :, 0] = self.red\n    tensor[:, :, 1] = self.green\n    tensor[:, :, 2] = self.blue\n    tensor[:, :, 3] = self.rededge\n    tensor[:, :, 4] = self.nir\n\n\n\n    return tensor\n</code></pre>"}]}